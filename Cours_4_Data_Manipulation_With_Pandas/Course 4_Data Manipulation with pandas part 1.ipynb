{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transforming Data Using Pandas \n",
    "\n",
    "> Chapter 1\n",
    "\n",
    ">> Data manipulation\n",
    "\n",
    ">> Data visualisation \n",
    "\n",
    "> Chapter 2 \n",
    "\n",
    ">> Summary Stats\n",
    "\n",
    ">> Counting\n",
    "\n",
    ">> Grouped Summary Stats\n",
    "\n",
    "> Chapter 3\n",
    "\n",
    ">> Subsetting using slicing \n",
    "\n",
    ">> Indexes and subsetting using indexes \n",
    "\n",
    "> Chapter 4 \n",
    "\n",
    ">> Plotting \n",
    "\n",
    ">> handling missing data \n",
    "\n",
    ">> Reading data into data frame \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> pandas is built on Numpy and Matplotlib \n",
    "\n",
    "> Numpy provides muti-dimensional array objects \n",
    "\n",
    "> Matplotlib is used for data visualisation \n",
    "\n",
    "> Pandas is very popular \n",
    "\n",
    "> Rectangular data / Tables is used for pandas \n",
    "\n",
    "> Different columns can have different data types\n",
    "\n",
    "> data.head() \n",
    "\n",
    ">> Shows top 5 rows but more can be viewed by passing the int value as asgument rg data.head(10)\n",
    "\n",
    "> data.info()\n",
    "\n",
    ">> Info() method display the name of the columns \n",
    "\n",
    "> data.shape()\n",
    "\n",
    ">> Shows number of rows X columns\n",
    "\n",
    "> data.describe()\n",
    "\n",
    ">> Provides some stats info about the data \n",
    "\n",
    "> data.values()\n",
    "\n",
    "> data.columns()\n",
    "\n",
    "> data.index()\n",
    "\n",
    "> Pandas is like swiss knife army \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inspecting a DataFrame\n",
    "When you get a new DataFrame to work with, the first thing you need to do is explore it and see what it contains. There are several useful methods and attributes for this.\n",
    "\n",
    ".head() returns the first few rows (the “head” of the DataFrame).\n",
    ".info() shows information on each of the columns, such as the data type and number of missing values.\n",
    ".shape returns the number of rows and columns of the DataFrame.\n",
    ".describe() calculates a few summary statistics for each column.\n",
    "homelessness is a DataFrame containing estimates of homelessness in each U.S. state in 2018. The individual column is the number of homeless individuals not part of a family with children. The family_members column is the number of homeless individuals part of a family with children. The state_pop column is the state's total population.\n",
    "\n",
    "pandas is imported for you.\n",
    "\n",
    "## Instructions 1/4\n",
    "\n",
    "\n",
    "> Import pandas using the alias pd.\n",
    "\n",
    "> Print a 2D NumPy array of the values in homelessness.\n",
    "\n",
    "> Print the column names of homelessness.\n",
    "\n",
    "> Print the index of homelessness.\n",
    "\n",
    "> Print the head of the homelessness DataFrame.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Head of the data => \n",
      "               region                 state  individuals  family_members  \\\n",
      "0  East South Central               Alabama       2570.0           864.0   \n",
      "1             Pacific                Alaska       1434.0           582.0   \n",
      "2            Mountain               Arizona       7259.0          2606.0   \n",
      "3  West South Central              Arkansas       2280.0           432.0   \n",
      "4             Pacific            California     109008.0         20964.0   \n",
      "5            Mountain              Colorado       7607.0          3250.0   \n",
      "6         New England           Connecticut       2280.0          1696.0   \n",
      "7      South Atlantic              Delaware        708.0           374.0   \n",
      "8      South Atlantic  District of Columbia       3770.0          3134.0   \n",
      "9      South Atlantic               Florida      21443.0          9587.0   \n",
      "\n",
      "   state_pop  \n",
      "0    4887681  \n",
      "1     735139  \n",
      "2    7158024  \n",
      "3    3009733  \n",
      "4   39461588  \n",
      "5    5691287  \n",
      "6    3571520  \n",
      "7     965479  \n",
      "8     701547  \n",
      "9   21244317  \n",
      "\n",
      "\n",
      "\n",
      "Data information => \n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 51 entries, 0 to 50\n",
      "Data columns (total 5 columns):\n",
      "region            51 non-null object\n",
      "state             51 non-null object\n",
      "individuals       51 non-null float64\n",
      "family_members    51 non-null float64\n",
      "state_pop         51 non-null int64\n",
      "dtypes: float64(2), int64(1), object(2)\n",
      "memory usage: 2.4+ KB\n",
      "None\n",
      "\n",
      "\n",
      "\n",
      "Desrbe data => \n",
      "         individuals  family_members     state_pop\n",
      "count      51.000000       51.000000  5.100000e+01\n",
      "mean     7225.784314     3504.882353  6.405637e+06\n",
      "std     15991.025083     7805.411811  7.327258e+06\n",
      "min       434.000000       75.000000  5.776010e+05\n",
      "25%      1446.500000      592.000000  1.777414e+06\n",
      "50%      3082.000000     1482.000000  4.461153e+06\n",
      "75%      6781.500000     3196.000000  7.340946e+06\n",
      "max    109008.000000    52070.000000  3.946159e+07\n",
      "\n",
      "\n",
      "\n",
      "General values =>\n",
      "[['East South Central' 'Alabama' 2570.0 864.0 4887681]\n",
      " ['Pacific' 'Alaska' 1434.0 582.0 735139]\n",
      " ['Mountain' 'Arizona' 7259.0 2606.0 7158024]\n",
      " ['West South Central' 'Arkansas' 2280.0 432.0 3009733]\n",
      " ['Pacific' 'California' 109008.0 20964.0 39461588]\n",
      " ['Mountain' 'Colorado' 7607.0 3250.0 5691287]\n",
      " ['New England' 'Connecticut' 2280.0 1696.0 3571520]\n",
      " ['South Atlantic' 'Delaware' 708.0 374.0 965479]\n",
      " ['South Atlantic' 'District of Columbia' 3770.0 3134.0 701547]\n",
      " ['South Atlantic' 'Florida' 21443.0 9587.0 21244317]\n",
      " ['South Atlantic' 'Georgia' 6943.0 2556.0 10511131]\n",
      " ['Pacific' 'Hawaii' 4131.0 2399.0 1420593]\n",
      " ['Mountain' 'Idaho' 1297.0 715.0 1750536]\n",
      " ['East North Central' 'Illinois' 6752.0 3891.0 12723071]\n",
      " ['East North Central' 'Indiana' 3776.0 1482.0 6695497]\n",
      " ['West North Central' 'Iowa' 1711.0 1038.0 3148618]\n",
      " ['West North Central' 'Kansas' 1443.0 773.0 2911359]\n",
      " ['East South Central' 'Kentucky' 2735.0 953.0 4461153]\n",
      " ['West South Central' 'Louisiana' 2540.0 519.0 4659690]\n",
      " ['New England' 'Maine' 1450.0 1066.0 1339057]\n",
      " ['South Atlantic' 'Maryland' 4914.0 2230.0 6035802]\n",
      " ['New England' 'Massachusetts' 6811.0 13257.0 6882635]\n",
      " ['East North Central' 'Michigan' 5209.0 3142.0 9984072]\n",
      " ['West North Central' 'Minnesota' 3993.0 3250.0 5606249]\n",
      " ['East South Central' 'Mississippi' 1024.0 328.0 2981020]\n",
      " ['West North Central' 'Missouri' 3776.0 2107.0 6121623]\n",
      " ['Mountain' 'Montana' 983.0 422.0 1060665]\n",
      " ['West North Central' 'Nebraska' 1745.0 676.0 1925614]\n",
      " ['Mountain' 'Nevada' 7058.0 486.0 3027341]\n",
      " ['New England' 'New Hampshire' 835.0 615.0 1353465]\n",
      " ['Mid-Atlantic' 'New Jersey' 6048.0 3350.0 8886025]\n",
      " ['Mountain' 'New Mexico' 1949.0 602.0 2092741]\n",
      " ['Mid-Atlantic' 'New York' 39827.0 52070.0 19530351]\n",
      " ['South Atlantic' 'North Carolina' 6451.0 2817.0 10381615]\n",
      " ['West North Central' 'North Dakota' 467.0 75.0 758080]\n",
      " ['East North Central' 'Ohio' 6929.0 3320.0 11676341]\n",
      " ['West South Central' 'Oklahoma' 2823.0 1048.0 3940235]\n",
      " ['Pacific' 'Oregon' 11139.0 3337.0 4181886]\n",
      " ['Mid-Atlantic' 'Pennsylvania' 8163.0 5349.0 12800922]\n",
      " ['New England' 'Rhode Island' 747.0 354.0 1058287]\n",
      " ['South Atlantic' 'South Carolina' 3082.0 851.0 5084156]\n",
      " ['West North Central' 'South Dakota' 836.0 323.0 878698]\n",
      " ['East South Central' 'Tennessee' 6139.0 1744.0 6771631]\n",
      " ['West South Central' 'Texas' 19199.0 6111.0 28628666]\n",
      " ['Mountain' 'Utah' 1904.0 972.0 3153550]\n",
      " ['New England' 'Vermont' 780.0 511.0 624358]\n",
      " ['South Atlantic' 'Virginia' 3928.0 2047.0 8501286]\n",
      " ['Pacific' 'Washington' 16424.0 5880.0 7523869]\n",
      " ['South Atlantic' 'West Virginia' 1021.0 222.0 1804291]\n",
      " ['East North Central' 'Wisconsin' 2740.0 2167.0 5807406]\n",
      " ['Mountain' 'Wyoming' 434.0 205.0 577601]]\n",
      "\n",
      "\n",
      "\n",
      "Columns of the data set => \n",
      "Index(['region', 'state', 'individuals', 'family_members', 'state_pop'], dtype='object')\n",
      "\n",
      "\n",
      "\n",
      "All the indexes of the data set => \n",
      "Int64Index([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
      "            17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33,\n",
      "            34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49,\n",
      "            50],\n",
      "           dtype='int64')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "homeData = pd.read_csv(r'C:\\Users\\Garvit\\Desktop\\Machine Learning\\Datacamp\\Cours_4_Data_Manipulation_With_Pandas\\homelessness.csv', index_col = 0)\n",
    "#print(data)\n",
    "print(\"Head of the data => \")\n",
    "print(homeData.head(10))\n",
    "print()\n",
    "print()\n",
    "print()\n",
    "\n",
    "print(\"Data information => \")\n",
    "print(homeData.info())\n",
    "print()\n",
    "print()\n",
    "print()\n",
    "print(\"Desrbe data => \")\n",
    "print(homeData.describe())\n",
    "print()\n",
    "print()\n",
    "print()\n",
    "print(\"General values =>\")\n",
    "print(homeData.values)\n",
    "print()\n",
    "print()\n",
    "print()\n",
    "print(\"Columns of the data set => \")\n",
    "print(homeData.columns)\n",
    "print()\n",
    "print()\n",
    "print()\n",
    "print(\"All the indexes of the data set => \")\n",
    "print(homeData.index)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sorting and Subsetting \n",
    "\n",
    "> data.sort_values('col_name', ascending = true)\n",
    "\n",
    "> data.sort_values(['col_1','col_2'], ascending = [True, False])\n",
    "\n",
    ">> To sort the rows according can also be done on multiple columns \n",
    "\n",
    "> data['col_name']\n",
    "\n",
    ">> To select or to zoom in particular columns \n",
    "\n",
    "> data[['col_1', 'col_2']]\n",
    "\n",
    ">> To select the multiple columns \n",
    "\n",
    "> data[data['col_1'] > 20] \n",
    "\n",
    ">> To select the rows in which the value of col_1 is > 20\n",
    "\n",
    "> data[data['breed']=='some_Sting']\n",
    "\n",
    "> filterd_data = data['col_name'].isin(['cond_1','cond_2'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sorting rows\n",
    "\n",
    "Finding interesting bits of data in a DataFrame is often easier if you change the order of the rows. You can sort the rows by passing a column name to .sort_values().\n",
    "\n",
    "In cases where rows have the same value (this is common if you sort on a categorical variable), you may wish to break the ties by sorting on another column. You can sort on multiple columns in this way by passing a list of column names.\n",
    "\n",
    "Sort on …\tSyntax\n",
    "one column\tdf.sort_values(\"breed\")\n",
    "multiple columns\tdf.sort_values([\"breed\", \"weight_kg\"])\n",
    "By combining .sort_values() with .head(), you can answer questions in the form, \"What are the top cases where…?\".\n",
    "\n",
    "homelessness is available and pandas is loaded as pd.\n",
    "\n",
    "## Instructions 1/3\n",
    "\n",
    "> Sort homelessness by the number of homeless individuals, from smallest to largest, and save this as homelessness_ind.\n",
    "\n",
    "> Print the head of the sorted DataFrame.\n",
    "\n",
    "\n",
    "> Sort homelessness by the number of homeless family_members in descending order, and save this as homelessness_fam.\n",
    "\n",
    "> Print the head of the sorted DataFrame.\n",
    "\n",
    "> Sort homelessness first by region (ascending), and then by number of family members (descending). Save this as homelessness_reg_fam.\n",
    "\n",
    "> Print the head of the sorted DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "Part 1 => \n",
      "                region         state  individuals  family_members  state_pop\n",
      "50            Mountain       Wyoming        434.0           205.0     577601\n",
      "34  West North Central  North Dakota        467.0            75.0     758080\n",
      "7       South Atlantic      Delaware        708.0           374.0     965479\n",
      "39         New England  Rhode Island        747.0           354.0    1058287\n",
      "45         New England       Vermont        780.0           511.0     624358\n",
      "\n",
      "\n",
      "\n",
      "Part 2 => \n",
      "                region          state  individuals  family_members  state_pop\n",
      "34  West North Central   North Dakota        467.0            75.0     758080\n",
      "50            Mountain        Wyoming        434.0           205.0     577601\n",
      "48      South Atlantic  West Virginia       1021.0           222.0    1804291\n",
      "41  West North Central   South Dakota        836.0           323.0     878698\n",
      "24  East South Central    Mississippi       1024.0           328.0    2981020\n",
      "\n",
      "\n",
      "\n",
      "Part 3 => \n",
      "                region      state  individuals  family_members  state_pop\n",
      "13  East North Central   Illinois       6752.0          3891.0   12723071\n",
      "35  East North Central       Ohio       6929.0          3320.0   11676341\n",
      "22  East North Central   Michigan       5209.0          3142.0    9984072\n",
      "49  East North Central  Wisconsin       2740.0          2167.0    5807406\n",
      "14  East North Central    Indiana       3776.0          1482.0    6695497\n"
     ]
    }
   ],
   "source": [
    "#print(homeData.head())\n",
    "print()\n",
    "print()\n",
    "print()\n",
    "print(\"Part 1 => \")\n",
    "homelessness_ind =  homeData.sort_values(\"individuals\")\n",
    "print(homelessness_ind.head())\n",
    "print()\n",
    "print()\n",
    "print()\n",
    "print(\"Part 2 => \")\n",
    "homelessness_fam =  homeData.sort_values(\"family_members\")\n",
    "print(homelessness_fam.head())\n",
    "print()\n",
    "print()\n",
    "print()\n",
    "print(\"Part 3 => \")\n",
    "homelessness_reg_fam = homeData.sort_values([\"region\",\"family_members\", ], ascending = [True, False])\n",
    "print(homelessness_reg_fam.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Subsetting columns\n",
    "\n",
    "When working with data, you may not need all of the variables in your dataset. Square brackets ([]) can be used to select only the columns that matter to you in an order that makes sense to you. To select only \"col_a\" of the DataFrame df, use\n",
    "\n",
    "df[\"col_a\"]\n",
    "To select \"col_a\" and \"col_b\" of df, use\n",
    "\n",
    "df[[\"col_a\", \"col_b\"]]\n",
    "homelessness is available and pandas is loaded as pd.\n",
    "\n",
    "## Instructions 1/3\n",
    "\n",
    "> Create a DataFrame called individuals that contains only the individuals column of homelessness.\n",
    "\n",
    "> Print the head of the result.\n",
    "\n",
    "\n",
    "> Create a DataFrame called state_fam that contains only the state and family_members columns of homelessness, in that order.\n",
    "\n",
    "> Print the head of the result.\n",
    "\n",
    "> Create a DataFrame called ind_state that contains the individuals and state columns of homelessness, in that order.\n",
    "\n",
    "> Print the head of the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0      2570.0\n",
      "1      1434.0\n",
      "2      7259.0\n",
      "3      2280.0\n",
      "4    109008.0\n",
      "Name: individuals, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Select the individuals column\n",
    "individuals = homeData['individuals']\n",
    "\n",
    "# Print the head of the result\n",
    "print(individuals.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        state  family_members\n",
      "0     Alabama           864.0\n",
      "1      Alaska           582.0\n",
      "2     Arizona          2606.0\n",
      "3    Arkansas           432.0\n",
      "4  California         20964.0\n"
     ]
    }
   ],
   "source": [
    "# Select the state and family_members columns\n",
    "state_fam = homeData[['state', 'family_members']]\n",
    "\n",
    "# Print the head of the result\n",
    "print(state_fam.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   individuals       state\n",
      "0       2570.0     Alabama\n",
      "1       1434.0      Alaska\n",
      "2       7259.0     Arizona\n",
      "3       2280.0    Arkansas\n",
      "4     109008.0  California\n"
     ]
    }
   ],
   "source": [
    "# Select only the individuals and state columns, in that order\n",
    "ind_state = homeData[['individuals', 'state']]\n",
    "\n",
    "# Print the head of the result\n",
    "print(ind_state.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Subsetting rows\n",
    "\n",
    "A large part of data science is about finding which bits of your dataset are interesting. One of the simplest techniques for this is to find a subset of rows that match some criteria. This is sometimes known as filtering rows or selecting rows.\n",
    "\n",
    "There are many ways to subset a DataFrame, perhaps the most common is to use relational operators to return True or False for each row, then pass that inside square brackets.\n",
    "\n",
    "dogs[dogs[\"height_cm\"] > 60]\n",
    "dogs[dogs[\"color\"] == \"tan\"]\n",
    "You can filter for multiple conditions at once by using the \"bitwise and\" operator, &.\n",
    "\n",
    "dogs[(dogs[\"height_cm\"] > 60) & (dogs[\"color\"] == \"tan\")]\n",
    "homelessness is available and pandas is loaded as pd.\n",
    "\n",
    "# Instructions 1/3\n",
    "\n",
    "> Filter homelessness for cases where the number of individuals is greater than ten thousand, assigning to ind_gt_10k. View the printed result.\n",
    "\n",
    "\n",
    "\n",
    "> Filter homelessness for cases where the USA Census region is \"Mountain\", assigning to mountain_reg. View the printed result.\n",
    "\n",
    "\n",
    "> Filter homelessness for cases where the number of family_members is less than one thousand and the region is \"Pacific\", assigning to fam_lt_1k_pac. View the printed result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                region       state  individuals  family_members  state_pop\n",
      "4              Pacific  California     109008.0         20964.0   39461588\n",
      "9       South Atlantic     Florida      21443.0          9587.0   21244317\n",
      "32        Mid-Atlantic    New York      39827.0         52070.0   19530351\n",
      "37             Pacific      Oregon      11139.0          3337.0    4181886\n",
      "43  West South Central       Texas      19199.0          6111.0   28628666\n",
      "47             Pacific  Washington      16424.0          5880.0    7523869\n"
     ]
    }
   ],
   "source": [
    "# Filter for rows where individuals is greater than 10000\n",
    "ind_gt_10k = homeData[homeData['individuals']> 10000]\n",
    "\n",
    "# See the result\n",
    "print(ind_gt_10k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      region       state  individuals  family_members  state_pop\n",
      "2   Mountain     Arizona       7259.0          2606.0    7158024\n",
      "5   Mountain    Colorado       7607.0          3250.0    5691287\n",
      "12  Mountain       Idaho       1297.0           715.0    1750536\n",
      "26  Mountain     Montana        983.0           422.0    1060665\n",
      "28  Mountain      Nevada       7058.0           486.0    3027341\n",
      "31  Mountain  New Mexico       1949.0           602.0    2092741\n",
      "44  Mountain        Utah       1904.0           972.0    3153550\n",
      "50  Mountain     Wyoming        434.0           205.0     577601\n"
     ]
    }
   ],
   "source": [
    "# Filter for rows where region is Mountain\n",
    "mountain_reg = homeData[homeData[\"region\"]==\"Mountain\"]\n",
    "\n",
    "# See the result\n",
    "print(mountain_reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    region   state  individuals  family_members  state_pop\n",
      "1  Pacific  Alaska       1434.0           582.0     735139\n"
     ]
    }
   ],
   "source": [
    "# Filter for rows where family_members is less than 1000 \n",
    "# and region is Pacific\n",
    "fam_lt_1k_pac = homeData[(homeData['family_members']<1000) &  (homeData['region'] == \"Pacific\")]\n",
    "\n",
    "# See the result\n",
    "print(fam_lt_1k_pac)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Subsetting rows by categorical variables\n",
    "\n",
    "Subsetting data based on a categorical variable often involves using the \"or\" operator (|) to select rows from multiple categories. This can get tedious when you want all states in one of three different regions, for example. Instead, use the .isin() method, which will allow you to tackle this problem by writing one condition instead of three separate ones.\n",
    "\n",
    "colors = [\"brown\", \"black\", \"tan\"]\n",
    "\n",
    "condition = dogs[\"color\"].isin(colors)\n",
    "\n",
    "dogs[condition]\n",
    "\n",
    "homelessness is available and pandas is loaded as pd.\n",
    "\n",
    "## Instructions 1/2\n",
    "\n",
    "> Filter homelessness for cases where the USA census region is \"South Atlantic\" or it is \"Mid-Atlantic\", assigning to south_mid_atlantic. View the printed result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            region                 state  individuals  family_members  \\\n",
      "7   South Atlantic              Delaware        708.0           374.0   \n",
      "8   South Atlantic  District of Columbia       3770.0          3134.0   \n",
      "9   South Atlantic               Florida      21443.0          9587.0   \n",
      "10  South Atlantic               Georgia       6943.0          2556.0   \n",
      "20  South Atlantic              Maryland       4914.0          2230.0   \n",
      "30    Mid-Atlantic            New Jersey       6048.0          3350.0   \n",
      "32    Mid-Atlantic              New York      39827.0         52070.0   \n",
      "33  South Atlantic        North Carolina       6451.0          2817.0   \n",
      "38    Mid-Atlantic          Pennsylvania       8163.0          5349.0   \n",
      "40  South Atlantic        South Carolina       3082.0           851.0   \n",
      "46  South Atlantic              Virginia       3928.0          2047.0   \n",
      "48  South Atlantic         West Virginia       1021.0           222.0   \n",
      "\n",
      "    state_pop  \n",
      "7      965479  \n",
      "8      701547  \n",
      "9    21244317  \n",
      "10   10511131  \n",
      "20    6035802  \n",
      "30    8886025  \n",
      "32   19530351  \n",
      "33   10381615  \n",
      "38   12800922  \n",
      "40    5084156  \n",
      "46    8501286  \n",
      "48    1804291  \n"
     ]
    }
   ],
   "source": [
    "# Subset for rows in South Atlantic or Mid-Atlantic regions\n",
    "regionsdata = ['South Atlantic','Mid-Atlantic']\n",
    "condition = homeData['region'].isin(regionsdata)\n",
    "\n",
    "south_mid_atlantic = homeData[condition]\n",
    "\n",
    "# See the result\n",
    "print(south_mid_atlantic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      region       state  individuals  family_members  state_pop\n",
      "2   Mountain     Arizona       7259.0          2606.0    7158024\n",
      "4    Pacific  California     109008.0         20964.0   39461588\n",
      "28  Mountain      Nevada       7058.0           486.0    3027341\n",
      "44  Mountain        Utah       1904.0           972.0    3153550\n"
     ]
    }
   ],
   "source": [
    "# The Mojave Desert states\n",
    "canu = [\"California\", \"Arizona\", \"Nevada\", \"Utah\"]\n",
    "condition = homeData['state'].isin(canu)\n",
    "# Filter for rows in the Mojave Desert states\n",
    "mojave_homelessness = homeData[condition]\n",
    "\n",
    "# See the result\n",
    "print(mojave_homelessness)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  New Columns \n",
    "\n",
    "> data['new_col'] = data['old_col']/10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding new columns\n",
    "\n",
    "You aren't stuck with just the data you are given. Instead, you can add new columns to a DataFrame. This has many names, such as transforming, mutating, and feature engineering.\n",
    "\n",
    "You can create new columns from scratch, but it is also common to derive them from other columns, for example, by adding columns together or by changing their units.\n",
    "\n",
    "homelessness is available and pandas is loaded as pd.\n",
    "\n",
    "## Instructions\n",
    "\n",
    "> Add a new column to homelessness, named total, containing the sum of the individuals and family_members columns.\n",
    "\n",
    "> Add another column to homelessness, named p_individuals, containing the proportion of homeless people in each state who are individuals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               region       state  individuals  family_members  state_pop  \\\n",
      "0  East South Central     Alabama       2570.0           864.0    4887681   \n",
      "1             Pacific      Alaska       1434.0           582.0     735139   \n",
      "2            Mountain     Arizona       7259.0          2606.0    7158024   \n",
      "3  West South Central    Arkansas       2280.0           432.0    3009733   \n",
      "4             Pacific  California     109008.0         20964.0   39461588   \n",
      "\n",
      "      total  p_individuals  \n",
      "0    3434.0       0.748398  \n",
      "1    2016.0       0.711310  \n",
      "2    9865.0       0.735834  \n",
      "3    2712.0       0.840708  \n",
      "4  129972.0       0.838704  \n"
     ]
    }
   ],
   "source": [
    "# Add total col as sum of individuals and family_members\n",
    "homeData['total'] = homeData['individuals'] + homeData['family_members']\n",
    "\n",
    "\n",
    "# Add p_individuals col as proportion of individuals\n",
    "homeData['p_individuals'] =  homeData['individuals']/ homeData['total']\n",
    "\n",
    "\n",
    "# See the result\n",
    "print(homeData.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combo-attack!\n",
    "You've seen the four most common types of data manipulation: sorting rows, subsetting columns, subsetting rows, and adding new columns. In a real-life data analysis, you can mix and match these four manipulations to answer a multitude of questions.\n",
    "\n",
    "In this exercise, you'll answer the question, \"Which state has the highest number of homeless individuals per 10,000 people in the state?\" Combine your new pandas skills to find out.\n",
    "\n",
    "## Instructions\n",
    "\n",
    "> Add a column to homelessness, indiv_per_10k, containing the number of homeless individuals per ten thousand people in each state.\n",
    "\n",
    "> Subset rows where indiv_per_10k is higher than 20, assigning to high_homelessness.\n",
    "\n",
    "> Sort high_homelessness by descending indiv_per_10k, assigning to high_homelessness_srt.\n",
    "\n",
    "> Select only the state and indiv_per_10k columns of high_homelessness_srt and save as result. Look at the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   state  indiv_per_10k\n",
      "8   District of Columbia      53.738381\n",
      "11                Hawaii      29.079406\n",
      "4             California      27.623825\n",
      "37                Oregon      26.636307\n",
      "28                Nevada      23.314189\n",
      "47            Washington      21.829195\n",
      "32              New York      20.392363\n"
     ]
    }
   ],
   "source": [
    "# Create indiv_per_10k col as homeless individuals per 10k state pop\n",
    "homeData[\"indiv_per_10k\"] = 10000 * homeData[\"individuals\"]/homeData[\"state_pop\"]\n",
    "\n",
    "\n",
    "# Subset rows for indiv_per_10k greater than 20\n",
    "high_homelessness = homeData[homeData['indiv_per_10k']> 20]\n",
    "\n",
    "\n",
    "# Sort high_homelessness by descending indiv_per_10k\n",
    "high_homelessness_srt = high_homelessness.sort_values('indiv_per_10k',ascending = False )\n",
    "\n",
    "# print(high_homelessness_srt.head())\n",
    "# From high_homelessness_srt, select the state and indiv_per_10k cols\n",
    "result = high_homelessness_srt[['state','indiv_per_10k']]\n",
    "\n",
    "# See the result\n",
    "print(result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
